{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOjXa042hkeMFT+NUMxbFXl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kennycaiguo/-LearnPytorchWithColab/blob/main/torch_tutorial_lesson1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16IXUb4NLIvw",
        "outputId": "286a0319-3869-4960-da17-f40ba0268bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3])\n",
            "tensor([False,  True,  True,  True])\n",
            "tensor([0, 1, 2, 3], dtype=torch.int16)\n",
            "tensor([0, 1, 2, 3], dtype=torch.int32)\n",
            "tensor([0, 1, 2, 3])\n",
            "tensor([0., 1., 2., 3.], dtype=torch.float16)\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([0., 1., 2., 3.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "mydevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "mytensor = torch.tensor([[1,2,3],[4,5,6]],dtype=torch.float32,device=mydevice,requires_grad=True) #创建tensor的时候可以指定使用cuda还是普通cpu建议使用cuda\n",
        "\n",
        "# print(mytensor)\n",
        "# print(mytensor.dtype)\n",
        "# print(mytensor.device)\n",
        "# print(mytensor.shape)\n",
        "# print(mytensor.requires_grad)\n",
        "\n",
        "# 可以创建一个空的tensor对象\n",
        "# empty_tensor = torch.tensor([]) # 创建空对象方法1\n",
        "# empty_tensor = torch.empty(size=(3,3)) # 创建空对象方法2\n",
        "# print(empty_tensor.shape)\n",
        "# print(empty_tensor.size())\n",
        "\n",
        "# 可以创建全部都是0的tensor对象\n",
        "# zero_tensor = torch.zeros(3,3)\n",
        "# print(zero_tensor)\n",
        "# print(zero_tensor.shape)\n",
        "\n",
        "# 可以创建全部都是1的tensor对象\n",
        "# one_tensor = torch.ones(2,5)\n",
        "# print(one_tensor)\n",
        "# print(one_tensor.shape)\n",
        "\n",
        "# 可以创建对角线是1,其他位置是0的tensor对象\n",
        "# eye_tensor = torch.eye(5,5)\n",
        "# print(eye_tensor)\n",
        "# print(eye_tensor.shape)\n",
        "\n",
        "# 可以用0-1的随机数来创建tensor对象\n",
        "# rnd_tensor = torch.rand(2,3)\n",
        "# print(rnd_tensor)\n",
        "# print(rnd_tensor.shape)\n",
        "\n",
        "# 还可以使用arange函数来创建\n",
        "# a_tensor = torch.arange(start=0,end=5,step=1)\n",
        "# print(a_tensor)\n",
        "# print(a_tensor.shape)\n",
        "\n",
        "# 还可以使用linspace函数来创建tensor\n",
        "# l_tensor = torch.linspace(start=0.1,end=1,steps=10)\n",
        "# print(l_tensor)\n",
        "# print(l_tensor.shape)\n",
        "\n",
        "# tensor转化为其他数据类型\n",
        "tensor1 = torch.arange(4)\n",
        "print(tensor1)\n",
        "print(tensor1.bool()) # 转化为布尔类型\n",
        "print(tensor1.short()) # 转化为短整型\n",
        "print(tensor1.int()) # 转化为整型\n",
        "print(tensor1.long()) # 转化为长整型\n",
        "\n",
        "print(tensor1.half()) # 转化为半精度浮点型 float16\n",
        "print(tensor1.float()) # 转化为单精度浮点型 float32\n",
        "print(tensor1.double()) # 转化为双精度浮点型 float64s"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ndarray=>tensor以及tensor->ndarray\n",
        "import numpy as np\n",
        "arr = np.zeros((5,5))\n",
        "#ndarray=>tensor\n",
        "tensor = torch.from_numpy(arr)\n",
        "print(tensor)\n",
        "print(type(tensor))\n",
        "\n",
        "#tensor->ndarray\n",
        "arr2 = tensor.numpy()\n",
        "print(arr2)\n",
        "print(type(arr2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFvEs8zRcKDn",
        "outputId": "31222511-42ce-494f-9fd3-42f4b833f640"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "<class 'torch.Tensor'>\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor类型的运算\n",
        "# add\n",
        "x = torch.tensor([1,2,3])\n",
        "y = torch.tensor([9,8,7])\n",
        "z1 = torch.empty(3)\n",
        "torch.add(x,y,out=z1)#调用torch的add方法,其实就是两个tensor对象对应的元素相加\n",
        "print(z1)\n",
        "z2 = torch.add(x,y)#调用torch的add方法,其实就是两个tensor对象对应的元素相加\n",
        "print(z2)\n",
        "z = x+y #直接进行相加,其实就是两个tensor对象对应的元素相加\n",
        "print(z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwNIWwubdJpX",
        "outputId": "fcc7ece2-a858-4da9-8e19-43e4b08b3178"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10., 10., 10.])\n",
            "tensor([10, 10, 10])\n",
            "tensor([10, 10, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#subtract\n",
        "res = x - y\n",
        "print(res)\n",
        "res = torch.subtract(x,y)\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AEEXGR6eTwH",
        "outputId": "0ce7a099-f4a0-40c3-e2a3-d28771e9e21b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-8, -6, -4])\n",
            "tensor([-8, -6, -4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# division\n",
        "res = torch.true_divide(x,y)\n",
        "print(res)\n",
        "res = x/y\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdgKHpunejC3",
        "outputId": "32dc4b56-441f-4327-8c29-1cb366a87b21"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1111, 0.2500, 0.4286])\n",
            "tensor([0.1111, 0.2500, 0.4286])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 上面的运算都不是原地操作,他们会返回新的tensor\n",
        "# 下面我们来学习原地操作这些函数都是带_的\n",
        "# 1.add_()\n",
        "t = torch.zeros(3)\n",
        "t.add_(x)\n",
        "# print(t)\n",
        "t += x # t = t + x\n",
        "# print(t)\n",
        "\n",
        "# 2.subtract_()\n",
        "t.subtract_(x)\n",
        "# print(t)\n",
        "t -= x\n",
        "# print(t)\n",
        "\n",
        "# 3.divide_()\n",
        "t1 = torch.tensor([2,4,6], dtype=torch.float32) # 奇怪,这里如果不把数据类型改为float,会报错\n",
        "t1.divide_(x)\n",
        "print(t1)"
      ],
      "metadata": {
        "id": "VY8CKr32kATV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6ece960-a9be-4299-c7fc-9c69336f0bc1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 指数操作\n",
        "# 写法1\n",
        "# cub = x.pow(3)\n",
        "# print(cub)\n",
        "# 写法2\n",
        "cub = x**3\n",
        "print(cub)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sODF_JROh48B",
        "outputId": "4e1e21cb-cbb3-4b2b-8e8d-93161867d3d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1,  8, 27])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor对象的比较\n",
        "print(x>0) # tensor([True, True, True]) 一个tensor和一个数字比较,也就是把这个tensor对象里面的所有元素都和这个数字比较,返回值是一个又布尔值组成的tensor\n",
        "# 两个tensor对象比较,也就是他们对应位置的元素的比较,(这两个tensor的形状必须完全相同)\n",
        "print(x<y) # tensor([True, True, True])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqJlKhkRiyq_",
        "outputId": "cdbc4fc3-6f62-447e-9d67-12840c3ee272"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True])\n",
            "tensor([True, True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#矩阵乘法,要做矩阵乘法,第一个矩阵的列数需要等于第二个矩阵的行数,然后结果的行数是第一个矩阵的行数,结果的列数是第二个矩阵的列数\n",
        "x1 = torch.rand((2,5))\n",
        "x2 = torch.rand((5,3))\n",
        "x3 = torch.mm(x1,x2) #矩阵乘法,方法1\n",
        "print(x3) # 是一个2行3列的tensor(是矩阵来的)tensor([[1.6750, 1.6855, 1.4011],[1.3710, 1.0602, 0.9070]])\n",
        "x4 = x1.mm(x2) # 矩阵乘法,写法2\n",
        "print(x4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YDnHj5sjhDI",
        "outputId": "6da751c3-c08e-4295-e903-7747dff01f0e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0695, 0.8425, 1.3662],\n",
            "        [2.0211, 2.2844, 2.2732]])\n",
            "tensor([[1.0695, 0.8425, 1.3662],\n",
            "        [2.0211, 2.2844, 2.2732]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 矩阵的幂运算\n",
        "matrix = torch.rand(5,5)\n",
        "matrix_exp = matrix.matrix_power(3)\n",
        "print(matrix_exp)\n",
        "matrix_exp2 = matrix**3 # 这种写法得到的结果和上面不一样!!!\n",
        "print(matrix_exp2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4K8R8CvLDqc",
        "outputId": "db669332-b467-4256-9869-c6ef37573059"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3.8743, 3.8256, 5.1538, 4.0212, 3.6105],\n",
            "        [4.6265, 4.5152, 6.1594, 4.7186, 4.4253],\n",
            "        [6.2076, 6.1248, 8.4498, 6.4324, 5.9229],\n",
            "        [5.3377, 5.3127, 7.3359, 5.5942, 5.0534],\n",
            "        [3.5366, 3.4530, 4.7783, 3.6131, 3.4238]])\n",
            "tensor([[4.8420e-02, 1.1302e-01, 7.1676e-01, 3.9025e-04, 1.2646e-01],\n",
            "        [9.9979e-02, 4.8740e-03, 3.4420e-01, 2.0070e-01, 9.3489e-01],\n",
            "        [3.1797e-01, 6.6804e-01, 9.2563e-01, 5.5308e-01, 4.5056e-02],\n",
            "        [7.0040e-01, 4.1553e-01, 1.3547e-01, 3.6260e-01, 1.8881e-01],\n",
            "        [2.7754e-02, 3.2511e-02, 2.0154e-01, 1.9822e-01, 2.2404e-02]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 两个tensor对应位的元素相乘\n",
        "res = x * y  #[1*9,2*8,3*7]\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPjq15oQL1hb",
        "outputId": "3e0c8916-a9e3-4e82-99ab-233f26e8179d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 9, 16, 21])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor矩阵的点乘\n",
        "dot_res = torch.dot(x,y) # [1*9 + 2*8 + 3*7]\n",
        "print(dot_res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LKUQ6GTMUeB",
        "outputId": "c5e83952-adb8-4a4b-f72e-3ad4df955ea7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(46)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#批量矩阵乘法,torch.bmm()\n",
        "batch = 32\n",
        "n = 10\n",
        "m = 20\n",
        "p = 30\n",
        "\n",
        "tensor1 = torch.rand((batch,n,m))\n",
        "tensor2 = torch.rand((batch,m,p))\n",
        "out_bmm = torch.bmm(tensor1,tensor2) # (batch,n,p)\n",
        "print(out_bmm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjST4SaBM-8F",
        "outputId": "9e7cfdae-ec87-4c91-fe71-6fdf24a3aeb8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[5.0408, 3.9031, 4.3576,  ..., 3.0568, 4.7929, 3.2972],\n",
            "         [5.4397, 4.6825, 5.2673,  ..., 4.2250, 6.7470, 4.9432],\n",
            "         [5.7779, 5.2390, 6.1961,  ..., 4.2946, 6.6419, 4.6348],\n",
            "         ...,\n",
            "         [5.6094, 5.4529, 4.6194,  ..., 4.2911, 7.2305, 4.8028],\n",
            "         [4.5664, 3.9362, 4.0528,  ..., 2.8152, 4.8406, 4.0744],\n",
            "         [5.3715, 4.9994, 4.9218,  ..., 3.1238, 5.8491, 3.8810]],\n",
            "\n",
            "        [[5.4019, 6.2067, 4.0780,  ..., 3.7039, 5.9432, 4.9837],\n",
            "         [4.8032, 4.9164, 3.5576,  ..., 3.3919, 4.9504, 4.4352],\n",
            "         [4.5536, 5.2467, 2.8115,  ..., 3.5215, 4.5710, 5.0998],\n",
            "         ...,\n",
            "         [5.0320, 5.1583, 3.5752,  ..., 3.9860, 5.5345, 4.1524],\n",
            "         [5.5878, 4.9522, 3.5586,  ..., 3.6543, 5.0998, 5.1382],\n",
            "         [6.9206, 6.4273, 5.2578,  ..., 4.3830, 6.3454, 6.4311]],\n",
            "\n",
            "        [[5.5481, 5.7331, 5.8435,  ..., 6.2551, 6.0613, 5.8118],\n",
            "         [4.6012, 4.6135, 5.4786,  ..., 5.5483, 4.5751, 4.7466],\n",
            "         [5.3829, 5.4369, 6.3903,  ..., 5.8481, 5.2942, 5.4035],\n",
            "         ...,\n",
            "         [5.6147, 5.2690, 6.2224,  ..., 5.5546, 6.0509, 5.4103],\n",
            "         [3.8110, 4.0156, 4.3282,  ..., 3.8938, 4.1403, 3.9480],\n",
            "         [3.7848, 3.7913, 4.5239,  ..., 4.7616, 4.0632, 4.1659]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[4.9758, 4.5890, 3.9968,  ..., 6.6234, 6.1444, 5.9582],\n",
            "         [4.0341, 4.0102, 2.4805,  ..., 5.0323, 4.2445, 3.7130],\n",
            "         [4.0866, 4.2846, 3.8068,  ..., 5.8253, 6.1755, 5.4156],\n",
            "         ...,\n",
            "         [3.2997, 3.9870, 2.5731,  ..., 5.2068, 3.7495, 4.7957],\n",
            "         [2.9801, 3.6633, 2.3229,  ..., 4.2407, 3.6192, 4.4751],\n",
            "         [4.4090, 4.4263, 3.4324,  ..., 6.9129, 6.1832, 5.8481]],\n",
            "\n",
            "        [[6.0639, 5.6394, 6.2757,  ..., 6.6451, 5.4768, 6.3877],\n",
            "         [4.5018, 4.7597, 4.4842,  ..., 5.0602, 4.5586, 4.7925],\n",
            "         [6.8444, 6.8976, 7.2292,  ..., 6.9386, 7.3679, 6.7968],\n",
            "         ...,\n",
            "         [5.5029, 5.2088, 5.1946,  ..., 4.5418, 4.9462, 5.4302],\n",
            "         [4.7279, 4.9316, 5.1714,  ..., 4.8125, 4.5497, 4.7967],\n",
            "         [6.1430, 6.2513, 6.5615,  ..., 7.1010, 6.0370, 6.0901]],\n",
            "\n",
            "        [[3.8027, 3.9272, 3.5863,  ..., 4.4341, 4.4401, 5.5370],\n",
            "         [5.0237, 5.7133, 4.4877,  ..., 6.4902, 5.3654, 6.5938],\n",
            "         [4.9156, 5.6376, 4.7998,  ..., 6.5584, 4.5758, 6.2084],\n",
            "         ...,\n",
            "         [4.3824, 4.6802, 3.7139,  ..., 4.2614, 4.6543, 5.3038],\n",
            "         [4.6718, 5.4557, 4.5789,  ..., 6.1320, 5.1302, 6.0291],\n",
            "         [3.5857, 4.7998, 4.4991,  ..., 4.9675, 3.6726, 4.6428]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 广播\n",
        "x1 = torch.rand((5,5))\n",
        "x2 = torch.rand((1,5))\n",
        "z = x1 - x2\n",
        "print(z)\n",
        "z = x1 ** x2\n",
        "print(z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii-bi4thOB_H",
        "outputId": "963a8e6a-f936-4cec-8133-17491ef8fe5b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0558, -0.6274,  0.1934, -0.2140, -0.3501],\n",
            "        [-0.1267, -0.5197,  0.0428,  0.1047,  0.1921],\n",
            "        [-0.0981,  0.1107,  0.4384,  0.4137, -0.1850],\n",
            "        [ 0.0504,  0.2233,  0.7067,  0.5599, -0.2856],\n",
            "        [-0.1940, -0.4505,  0.4669,  0.0871,  0.1908]])\n",
            "tensor([[0.6567, 0.1309, 0.9627, 0.4446, 0.4903],\n",
            "        [0.6004, 0.2859, 0.9349, 0.7701, 0.9382],\n",
            "        [0.6239, 0.8509, 0.9809, 0.9025, 0.6390],\n",
            "        [0.7312, 0.9314, 0.9922, 0.9493, 0.5502],\n",
            "        [0.5400, 0.3659, 0.9824, 0.7603, 0.9373]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 一些有用的tensor操作\n",
        "total = torch.sum(x) # 求和\n",
        "# print(total) # tensor(6)\n",
        "#最大值\n",
        "val,index = torch.max(x,dim=0) # 也可以x.max(dim=0)\n",
        "# print(val,index) # tensor(3) tensor(2)\n",
        "#最小值\n",
        "val,index = torch.min(x,dim=0) # 也可以x.min(dim=0)\n",
        "# print(val,index) # tensor(1) tensor(0)\n",
        "#绝对值\n",
        "abs_val = torch.abs(x) # 注意:这个方法没有dim参数,也可以x.abs()\n",
        "# print(abs_val)\n",
        "# 获取最大的元素并且返回他的索引\n",
        "mx_idx = torch.argmax(x) # 或者: mx_idx = torch.argmax(x,dim=0)也可以x.argmax(dim=0)\n",
        "# print(mx_idx)\n",
        "# 获取最小的元素并且返回他的索引\n",
        "mn_idx = torch.argmin(x) # 或者: mx_idx = torch.argmin(x,dim=0)\n",
        "# print(mn_idx)\n",
        "# 均值\n",
        "mean = torch.mean(x.float(),dim=0)\n",
        "# print(mean)\n",
        "\n",
        "# 判断两个tensor是否相等\n",
        "ret = torch.eq(x,y)\n",
        "# print(ret)\n",
        "# 判断两个tensor是否不等\n",
        "ret = torch.ne(x,y)\n",
        "# print(ret)\n",
        "\n",
        "#排序\n",
        "sorted_y,indices = torch.sort(y,dim=0,descending=False) #升序排列\n",
        "# print(sorted_y)\n",
        "# print(indices)\n",
        "\n",
        "#clamp(data,min=0) 如果data里面的元素小于这个min的值,就会把他们设置为min值,他也有一个max参数,如果data的元素大于这个max,就会强制把它设置为max\n",
        "data = torch.tensor([-2,-1,0,2,4,5])\n",
        "data2 = torch.clamp(data,min=0) # tensor([0, 0, 0, 2, 4, 5])\n",
        "print(data2)\n",
        "data = torch.tensor([-2,-1,0,2,4,5,7,8,9])\n",
        "data2 = torch.clamp(data,min=0,max=7) # tensor([0, 0, 0, 2, 4, 5, 7, 7, 7])\n",
        "print(data2)\n",
        "\n",
        "# any()只要有一个元素符合条件,就会返回True\n",
        "res = torch.any(data)\n",
        "# print(res) # tensor(True)\n",
        "# all()只有所有的元素符合条件,才返回True\n",
        "res = torch.all(data)\n",
        "print(res) # tensor(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ5l7Qz6P4pt",
        "outputId": "3bb7befd-5b53-4649-b62b-e071749ee71c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 2, 4, 5])\n",
            "tensor([0, 0, 0, 2, 4, 5, 7, 7, 7])\n",
            "tensor(False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 索引操作\n",
        "batch_size = 10\n",
        "features = 25\n",
        "t = torch.rand((batch_size,features))\n",
        "# print(t[0].shape) # torch.Size([25])\n",
        "# print(t[:,0].shape) # torch.Size([10])\n",
        "# print(t[2,0:10]) # tensor([0.3433, 0.5274, 0.5691, 0.8528, 0.2644, 0.2485, 0.0693, 0.1275, 0.3163,0.5014]) 得到一个1行10列的tensor\n",
        "\n",
        "t[0,0] = 10 #修改第一个元素的值\n",
        "# print(t)\n",
        "\n",
        "# 用索引选取你需要的元素\n",
        "x = torch.arange(10)\n",
        "# print(x)\n",
        "indices = [2,5,8]\n",
        "# print(x[indices]) # tensor([2, 5, 8])\n",
        "\n",
        "# 可以指定行数和列数,这个有点复杂需要慢慢理解\n",
        "x = torch.rand((3,5))\n",
        "print(x)\n",
        "rows = torch.tensor([1,0]) # 表示需要的行索引是1和0\n",
        "cols = torch.tensor([4,0]) # 表示需要的列索引是4和0\n",
        "# print(x[rows,cols]) # 根据位置的配对,获取元素x[1,4]和x[0,0]\n",
        "\n",
        "# 条件索引\n",
        "x = torch.arange(10)\n",
        "print(x[(x<2)|(x>8)]) # tensor([0, 1, 9])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEzNSxttbO8g",
        "outputId": "553ed21f-657c-4763-e8d5-508323825d6e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8158, 0.5149, 0.2647, 0.4535, 0.1050],\n",
            "        [0.3884, 0.1541, 0.5291, 0.4398, 0.9768],\n",
            "        [0.3795, 0.9225, 0.3936, 0.8032, 0.8027]])\n",
            "tensor([0, 1, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ha7E_1zjdUX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}